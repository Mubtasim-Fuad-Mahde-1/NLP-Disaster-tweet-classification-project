# -*- coding: utf-8 -*-
"""CSE440 Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10JaUBcjm3fRXVaedp-IQv6fI1_Iy4Ea8

# Import Library and file path
"""

data_file_path = 'CSE440_data.csv' #defualt data file path if in the same directory
glove_300dtxt_path = '/content/drive/MyDrive/CSE440/glove.6B.300d.txt' # change the file path based on the glove embedding destination path
# set glove path "glove.6B.300d.txt" if in the same directory

!pip install numpy pandas scikit-learn tensorflow keras nltk matplotlib seaborn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
import keras
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from keras.models import Sequential
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import EarlyStopping
from collections import Counter

nltk.download('stopwords')
nltk.download('wordnet')

"""# Import Data"""

try:
    df = pd.read_csv(data_file_path)
except:
    from google.colab import drive
    drive.mount('/content/drive')
    df = pd.read_csv('/content/drive/MyDrive/CSE440/CSE440_data.csv')
df

"""#Data Visualization"""

target_counts = df['target'].value_counts()

plt.figure(figsize=(8, 6))
bars = plt.bar(target_counts.index, target_counts.values, color=['lightgreen', 'salmon'])
plt.xlabel('Target')
plt.ylabel('Number of Instances')
plt.title('Distribution of Target Classes')
plt.xticks([0, 1], ['0', '1'])

for bar in bars:
  yval = bar.get_height()
  plt.text(bar.get_x() + bar.get_width()/2, yval, yval, ha='center', va='bottom')


plt.show()

disaster_tweets = df[df['target'] == 1]['text']

all_words_disaster = []
for tweet in disaster_tweets:
  words = tweet.lower().split()
  all_words_disaster.extend(words)

word_counts_disaster = Counter(all_words_disaster)

not_disaster_tweets = df[df['target'] == 0]['text']

all_words_not_disaster = []
for tweet in not_disaster_tweets:
  words = tweet.lower().split()
  all_words_not_disaster.extend(words)

word_counts_not_disaster = Counter(all_words_not_disaster)

unique_disaster_words = {word: count for word, count in word_counts_disaster.items() if word not in word_counts_not_disaster}
unique_not_disaster_words = {word: count for word, count in word_counts_not_disaster.items() if word not in word_counts_disaster}


top_30_unique_disaster_words = dict(sorted(unique_disaster_words.items(), key=lambda item: item[1], reverse=True)[:30])
top_30_unique_not_disaster_words = dict(sorted(unique_not_disaster_words.items(), key=lambda item: item[1], reverse=True)[:30])

plt.figure(figsize=(12, 6))
plt.bar(top_30_unique_disaster_words.keys(), top_30_unique_disaster_words.values())
plt.xlabel("Words")
plt.ylabel("Frequency")
plt.title("Frequency Distribution of Top 30  Words Unique to class 1")
plt.xticks(rotation=45, ha='right')

for i, (word, count) in enumerate(top_30_unique_disaster_words.items()):
  plt.text(i, count, str(count), ha='center', va='bottom')

plt.show()


plt.figure(figsize=(12, 6))
plt.bar(top_30_unique_not_disaster_words.keys(), top_30_unique_not_disaster_words.values())
plt.xlabel("Words")
plt.ylabel("Frequency")
plt.title("Frequency Distribution of Top 30  Words Unique to class 0")
plt.xticks(rotation=45, ha='right')

for i, (word, count) in enumerate(top_30_unique_not_disaster_words.items()):
  plt.text(i, count, str(count), ha='center', va='bottom')

plt.show()

"""# Data split 0.9 ratio"""

df = df.drop(['id', 'keyword', 'location'], axis=1)

from sklearn.model_selection import train_test_split

X = df['text']
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42) #randomly selecting data points to split with seed/pattern selected as 42

"""# Data Sanitization"""

import re

def sanitize_text(text):
    text = str(text)
    text = text.lower()
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r'\d+', '', text)  # Remove numbers
    text = re.sub(r'(.)\1{2,}', r'\1', text)  # Remove characters repeated more than twice
    text = re.sub(r'\s+', ' ', text).strip()  # Replace multiple spaces with a single space
    return text

X_train = X_train.apply(sanitize_text)
X_test = X_test.apply(sanitize_text)
X_train

from collections import Counter

word_counts = Counter()
for text in X_train:
  for word in text.split():
    word_counts[word] += 1

unique_words_freq_more_than_1 = sum(1 for count in word_counts.values() if count > 1)
print("Number of unique words with frequency more than 1:", unique_words_freq_more_than_1)

"""# Tokenization"""

tokenizer = Tokenizer(num_words=10000)
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

X_train_pad = pad_sequences(X_train_seq)

max_length_X_train_pad = len(X_train_pad[0])
for i in range(1, len(X_train_pad)):
  if len(X_train_pad[i]) > max_length_X_train_pad:
    max_length_X_train_pad = len(X_train_pad[i])

print("Max length of X_train_pad:", max_length_X_train_pad)
max_length = max_length_X_train_pad

X_test_pad = pad_sequences(X_test_seq, max_length)

"""# Word embedding"""

import numpy as np

embeddings_index = {}
with open(glove_300dtxt_path, encoding='utf-8') as f:
    for line in f:
        values = line.split()
        word = values[0]
        coefs = np.asarray(values[1:], dtype='float32')
        embeddings_index[word] = coefs

vocab_size = 10000
embedding_dim = 300

embedding_matrix = np.zeros((vocab_size, embedding_dim))
for word, i in tokenizer.word_index.items():
    if i < vocab_size:
        embedding_vector = embeddings_index.get(word)
        if embedding_vector is not None:
            embedding_matrix[i] = embedding_vector

"""# Model Evalutation function"""

def f1_score(y_true, y_pred):
    y_true = K.cast(y_true, 'float32')
    y_pred = K.cast(y_pred, 'float32')
    def recall(y_true, y_pred):
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
        recall = true_positives / (possible_positives + K.epsilon())
        return recall

    def precision(y_true, y_pred):
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
        precision = true_positives / (predicted_positives + K.epsilon())
        return precision

    precision_value = precision(y_true, y_pred)
    recall_value = recall(y_true, y_pred)

    f1 = 2 * ((precision_value * recall_value) / (precision_value + recall_value + K.epsilon()))
    return f1

"""# Model Implementation"""

model = Sequential()
model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False))
model.add(Bidirectional(LSTM(128, dropout=0.1, recurrent_dropout=0.1, return_sequences=False)))
model.add(Dense(1, activation='sigmoid'))
model.build(input_shape=(None, max_length))
model.summary()

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_score])

model_gru = Sequential()
model_gru.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False))
model_gru.add(Bidirectional(keras.layers.GRU(128, dropout=0.1, recurrent_dropout=0.1, return_sequences=True)))
model_gru.add(Bidirectional(keras.layers.GRU(64, dropout=0.1, recurrent_dropout=0.1, return_sequences=False)))
model_gru.add(Dense(1, activation='sigmoid'))
model_gru.build(input_shape=(None, max_length))

model_gru.summary()

model_gru.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_score])

num_epochs = 30
early_stop = EarlyStopping(monitor='val_loss', patience=2)

np.random.seed(42)
history = model.fit(X_train_pad, y_train, batch_size=64, epochs=num_epochs, validation_split=0.1,callbacks = [early_stop])
history_gru = model_gru.fit(X_train_pad, y_train, batch_size=64, epochs=num_epochs, validation_split=0.1, callbacks=[early_stop])

"""# Model Evaluation"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy (LSTM)')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()


plt.plot(history_gru.history['accuracy'])
plt.plot(history_gru.history['val_accuracy'])
plt.title('Model Accuracy (GRU)')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

from sklearn.metrics import accuracy_score, classification_report

y_pred = (model.predict(X_test_pad) > 0.5).astype("int32")
loss, accuracy, f1 = model.evaluate(X_test_pad, y_test, verbose=0)
print("BiLSTM Model:")
print("Loss:", loss)
print("Accuracy:", accuracy)
print("F1 Score:", f1)
print("Accuracy: ", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

y_pred = (model_gru.predict(X_test_pad) > 0.5).astype("int32")
loss_gru, accuracy_gru, f1_gru = model_gru.evaluate(X_test_pad, y_test, verbose=0)
print("GRU Model:")
print("Loss:", loss_gru)
print("Accuracy:", accuracy_gru)
print("F1 Score:", f1_gru)
print("Accuracy: ", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.metrics import confusion_matrix
import seaborn as sns

y_pred_lstm = (model.predict(X_test_pad) > 0.5).astype("int32")

cm_lstm = confusion_matrix(y_test, y_pred_lstm)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_lstm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted 0', 'Predicted 1'],
            yticklabels=['Actual 0', 'Actual 1'])
plt.title('Confusion Matrix - LSTM Model')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

y_pred_gru = (model_gru.predict(X_test_pad) > 0.5).astype("int32")

cm_gru = confusion_matrix(y_test, y_pred_gru)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_gru, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted 0', 'Predicted 1'],
            yticklabels=['Actual 0', 'Actual 1'])
plt.title('Confusion Matrix - GRU Model')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

try:
    model.save('disaster_tweet_model_lstm.5')
    model_gru.save('disaster_tweet_model_gru.5')
except:
    model.save('/content/drive/MyDrive/CSE440/disaster_tweet_model.h5')
    model_gru.save('/content/drive/MyDrive/CSE440/disaster_tweet_model_gru.h5')